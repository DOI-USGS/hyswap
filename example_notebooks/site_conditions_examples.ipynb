{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Visualization of Streamflow Conditions at Streamgages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides a demonstration of the use of [hyswap](https://doi-usgs.github.io/hyswap/) python package for calculating streamflow percentiles and then visualizing streamflow conditions at multiple streamflow gages. \n",
    "\n",
    "This example notebook relies on use of the [dataretrieval](https://github.com/DOI-USGS/dataRetrieval) package for downloading streamflow information from USGS Water Data for the Nation as well as the [geopandas](https://geopandas.org/) package for mapping functionality. All of the other packages used in this notebook are either part of the standard python library or are dependencies of hyswap.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run commented lines below to install geopandas and mapping dependencies from within the notebook\n",
    "#import sys\n",
    "#!{sys.executable} -m pip install geopandas folium mapclassify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataretrieval import waterdata\n",
    "from hyswap import utils, percentiles\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from zoneinfo import ZoneInfo\n",
    "\n",
    "from tqdm import tqdm # used for progress bar indicators\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # ignore warnings from dataretrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** The `tqdm` package is used in for-loops in this notebook to show a data download progress bar, which may be informative to the user. The specification below (`disable_tdqm`) determines whether this progress bar is displayed when the notebook renders. It is set to `True` when rendering the notebook in the `hyswap` GitHub documentation site. To see the progress bars in this notebook, set `disable_tqdm=False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disable_tqdm=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Helper Functions\n",
    "The `hyswap` package provides functionality for calculating non-interpretive streamflow statistics but does not provide functionality for correcting invalid data or geospatial capabilities for mapping. Here we setup some simple helper functions we can re-use throughout the notebook to QAQC data and create maps. We will be using data from `dataretrieval`, which returns geodataframes if `geopandas` is installed in your environment. If your dataset does not include geometry information, you will need to manually specify it using `geopandas.GeoDataFrame()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data QAQC function for provisional USGS data\n",
    "def qaqc_usgs_data(df, data_column_name):\n",
    "    #replace invalid -999999 values with NA\n",
    "    df[data_column_name] = df[data_column_name].replace(-999999, np.nan)\n",
    "    # add any additional QAQC steps needed\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gage_condition_map(gage_df, flow_data_type, flow_data_col, map_schema, streamflow_data_type):\n",
    "        # Format date and set to str type for use in map tooltips\n",
    "        if flow_data_type == 'instantaneous':\n",
    "                gage_df['Date'] = gage_df['time'].dt.strftime('%Y-%m-%d %H:%M')\n",
    "        elif flow_data_type == 'daily':\n",
    "                gage_df['Date'] = gage_df['time'].dt.strftime('%Y-%m-%d')\n",
    "        gage_df = gage_df.drop('time', axis=1)\n",
    "        # create colormap for map from hyswap schema\n",
    "        schema = utils.retrieve_schema(map_schema)\n",
    "        flow_cond_cmap = schema['colors']\n",
    "        if 'low_color' in schema:\n",
    "                flow_cond_cmap = [schema['low_color']] + flow_cond_cmap\n",
    "        if 'high_color' in schema:\n",
    "                flow_cond_cmap = flow_cond_cmap + [schema['high_color']]\n",
    "        # if creating a drought map, set handling of non-drought flows\n",
    "        if map_schema in ['WaterWatch_Drought', 'NIDIS_Drought']:\n",
    "                gage_df['flow_cat'] = gage_df['flow_cat'].cat.add_categories('Other')\n",
    "                gage_df.loc[gage_df['flow_cat'].isnull(), 'flow_cat'] = 'Other'\n",
    "                flow_cond_cmap = flow_cond_cmap + ['#e3e0ca'] # light taupe\n",
    "        # set NA values to \"Not Ranked\" category\n",
    "        gage_df['flow_cat'] = gage_df['flow_cat'].cat.add_categories('Not Ranked')\n",
    "        gage_df.loc[gage_df['est_pct'].isna(), 'flow_cat'] = 'Not Ranked'\n",
    "        flow_cond_cmap = flow_cond_cmap + ['#d3d3d3'] # light grey\n",
    "        # renaming columns with user friendly names for map\n",
    "        gage_df = gage_df.rename(columns={flow_data_col:'Discharge (cfs)',\n",
    "                                                'est_pct':'Estimated Percentile',\n",
    "                                                'monitoring_location_id':'USGS Gage ID',\n",
    "                                                'monitoring_location_name':'Streamgage Name',\n",
    "                                                'flow_cat':'Streamflow Category'})\n",
    "        # Create map\n",
    "        m = gage_df.set_crs(crs=\"EPSG:4326\").to_crs(\"EPSG:5070\").explore(column=\"Streamflow Category\",\n",
    "                                cmap=flow_cond_cmap,\n",
    "                                tooltip=[\"USGS Gage ID\", \"Streamgage Name\", \"Streamflow Category\", \"Discharge (cfs)\", \"Estimated Percentile\", \"Date\"],\n",
    "                                tiles=\"CartoDB Positron\",\n",
    "                                marker_kwds=dict(radius=5),\n",
    "                                legend_kwds=dict(caption=streamflow_data_type + '<br> Streamflow  Category'))\n",
    "        return m #returns a folium map object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Downloading and Processing\n",
    "Utilize an example state to select streamgages for generating various flow condition maps. Certain past days selected in the notebook are relevant to using the state of Vermont as an example, but the notebook can be run for any state. Next, find all stream sites active in the last year within the state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| tbl-cap: List of streamgage sites active within the last week\n",
    "state = 'Vermont'\n",
    "# Query Water Data APIs for what monitoring locations were active within the last week\n",
    "active_time_series,_ = waterdata.get_time_series_metadata(\n",
    "    state_name=state,\n",
    "    parameter_code='00060',\n",
    "    end_utc='P1W',\n",
    "    skip_geometry=True\n",
    "    )\n",
    "# Figure out which of these monitoring locations are streams\n",
    "# and grab their latitude/longitude information\n",
    "active_stream_gages,_ = waterdata.get_monitoring_locations(\n",
    "    monitoring_location_id=active_time_series['monitoring_location_id'].unique().tolist(),\n",
    "    site_type_code='ST',\n",
    "    properties=['monitoring_location_id', 'agency_code', 'monitoring_location_name', 'county_name', \n",
    "                'drainage_area', 'site_type', 'hydrologic_unit_code', 'altitude', 'vertical_datum', 'original_horizontal_datum']\n",
    ")\n",
    "\n",
    "display(active_stream_gages.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve Streamflow Data from the Water Data APIs\n",
    "For the monitoring locations identified above, download all historical daily streamflow data, from the beginning of each gage's flow record up until present. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a python dictionary of dataframes by site id number\n",
    "flow_data = {}\n",
    "\n",
    "for StaID in tqdm(active_stream_gages['monitoring_location_id'].tolist(), disable=disable_tqdm, desc=\"Downloading USGS Flow Data for Sites\"):\n",
    "    flow_data[StaID],_ = waterdata.get_daily(\n",
    "        monitoring_location_id=StaID,\n",
    "        parameter_code='00060',\n",
    "        statistic_id='00003', # mean daily discharge\n",
    "        skip_geometry=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Variable Streamflow Percentile Thresholds\n",
    "For the sites identified above, calculate streamflow percentile thresholds at 0, 1, 5, 10, ... , 90, 95, 99, 100 percentiles.\n",
    "\n",
    "Note that when using the default settings of [calculate_fixed_percentile_threshold()](https://doi-usgs.github.io/hyswap/reference/index.html#hyswap.percentiles.calculate_variable_percentile_thresholds_by_day) it is common for NA values to be returned for the highest/lowest percentile thresholds such as 1 and 99. This is because a very long streamflow record (100+ years) is required to have sufficient observations to calculate the 99th or 1st percentile of streamflow for a given day when using the default settings of `method=weibull` with `mask_out_of_range=True`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define what percentile levels (thresholds) that we want to calculate.\n",
    "# Intervals of 5 or less are recommended to have sufficient levels to interpolate between in later calculations. \n",
    "# Note that 0 and 100 percentile levels are ignored, refer to min and max values returned instead.\n",
    "percentile_levels = np.concatenate((np.array([1]), np.arange(5,96,5), np.array([99])), axis=0)\n",
    "print(percentile_levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentile_values = {}\n",
    "for StaID in tqdm(active_stream_gages['monitoring_location_id'], disable=disable_tqdm, desc=\"Processing Sites\"):\n",
    "    if flow_data[StaID].shape[0] > 0:\n",
    "        # Filter data as only approved data in the Water Data APIs should be used to calculate statistics\n",
    "        df = utils.filter_approved_data(flow_data[StaID], 'approval_status')\n",
    "        percentile_values[StaID] = percentiles.calculate_variable_percentile_thresholds_by_day(\n",
    "            df, \n",
    "            data_column_name='value',\n",
    "            date_column_name='time',\n",
    "            percentiles=percentile_levels\n",
    "            )\n",
    "    else:\n",
    "        print('No standard discharge data found for site ' + StaID + ', skipping')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| tbl-cap: Sample of calculated variable streamflow percentile thresholds for first site in list\n",
    "display(percentile_values[list(percentile_values.keys())[0]].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Current Flow Conditions Map for Daily Mean Streamflow\n",
    "\n",
    "### Retrieve most recent (yesterday) daily mean streamflow\n",
    "Data from yesterday will still be provisional, so they will not have been used to generate historical percentiles. We will pull these values from the `flow_data` dictionary and make a dataframe for calculating percentiles and mapping. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yesterday = datetime.strftime(datetime.now(tz=ZoneInfo(\"US/Eastern\")) - timedelta(1), '%Y-%m-%d')\n",
    "\n",
    "recent_dvs = pd.DataFrame()\n",
    "\n",
    "for StaID in active_stream_gages['monitoring_location_id'].tolist():\n",
    "    df = flow_data[StaID]\n",
    "    yesterday_row = df[df['time'] == yesterday]\n",
    "    recent_dvs = pd.concat([recent_dvs, yesterday_row])\n",
    "\n",
    "recent_dvs = qaqc_usgs_data(recent_dvs, 'value').drop(columns='geometry')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorize streamflow based on calculated percentile values\n",
    "Calculate estimated streamflow percentile for the new data by interpolating against the previously calculated percentile threshold levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate percentiles\n",
    "df = pd.DataFrame()\n",
    "for StaID, site_df in recent_dvs.groupby(by=\"monitoring_location_id\", group_keys=False):\n",
    "    if StaID in list(percentile_values.keys()):\n",
    "        if not percentile_values[StaID].isnull().all().all():\n",
    "            percentile_df = percentiles.calculate_multiple_variable_percentiles_from_values(\n",
    "            site_df,\n",
    "            data_column_name = 'value',\n",
    "            percentile_df = percentile_values[StaID],\n",
    "            date_column_name = 'time')\n",
    "            df = pd.concat([df, percentile_df])\n",
    "# categorize streamflow by the estimated streamflow percentiles\n",
    "df = utils.categorize_flows(df, 'est_pct', schema_name=\"NWD\")\n",
    "df = df.reset_index(level='time')\n",
    "# Prep Data for mapping by joining site information and flow data  \n",
    "gage_df = pd.merge(active_stream_gages, df, how=\"right\", on=\"monitoring_location_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Map of Streamflow Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| fig-cap: Map showing most recent daily mean streamflow and corresponding flow conditions\n",
    "map = create_gage_condition_map(\n",
    "    gage_df=gage_df,\n",
    "    flow_data_type='daily',\n",
    "    flow_data_col='value',\n",
    "    map_schema='NWD',\n",
    "    streamflow_data_type='Current Daily Mean'\n",
    "    )\n",
    "display(map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Map of Streamflow Conditions using Alternative Categorization Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| fig-cap: Map showing most recent daily mean streamflow and corresponding flow conditions using a brown-blue schema\n",
    "\n",
    "# Prep Data for mapping by joining site information and flow data \n",
    "map = create_gage_condition_map(\n",
    "    gage_df=gage_df,\n",
    "    flow_data_type='daily',\n",
    "    flow_data_col='value',\n",
    "    map_schema='WaterWatch_BrownBlue',\n",
    "    streamflow_data_type='Current Daily Mean'\n",
    "    )\n",
    "display(map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a \"Real-Time\" Flow Conditions Map for Instantaneous Streamflow\n",
    "\n",
    "### Retrieve most recent instantaneous streamflow records\n",
    "Download data from the Water Data APIs and calculate corresponding streamflow percentile for the most recent instantaneous discharge measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recent_ivs,_ = waterdata.get_latest_continuous(\n",
    "    monitoring_location_id=active_stream_gages['monitoring_location_id'].tolist(),\n",
    "    parameter_code='00060',\n",
    "    skip_geometry=True\n",
    "    )\n",
    "recent_ivs = qaqc_usgs_data(recent_ivs, 'value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorize streamflow based on calculated percentile values\n",
    "Calculate estimated streamflow percentile for the new instantaneous data by interpolating against the previously calculated percentile threshold levels from daily streamflow records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate percentiles\n",
    "df = pd.DataFrame()\n",
    "for StaID, site_df in recent_ivs.groupby(by=\"monitoring_location_id\", group_keys=False):\n",
    "    if StaID in list(percentile_values.keys()):\n",
    "        if not percentile_values[StaID].isnull().all().all():\n",
    "            percentile_df = percentiles.calculate_multiple_variable_percentiles_from_values(\n",
    "            site_df,\n",
    "            data_column_name = 'value',\n",
    "            percentile_df = percentile_values[StaID],\n",
    "            date_column_name = 'time')\n",
    "            df = pd.concat([df, percentile_df])\n",
    "# categorize streamflow by the estimated streamflow percentiles\n",
    "df = utils.categorize_flows(df, 'est_pct', schema_name=\"NWD\")\n",
    "df = df.tz_convert(tz='US/Eastern')\n",
    "df = df.reset_index(level='time')\n",
    "# Prep Data for mapping by joining site information and flow data  \n",
    "gage_df = pd.merge(active_stream_gages, df, how=\"right\", on=\"monitoring_location_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Map of Real-Time Streamflow Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| fig-cap: Map showing most real-time streamflow conditions\n",
    "map = create_gage_condition_map(\n",
    "    gage_df=gage_df,\n",
    "    flow_data_type='instantaneous',\n",
    "    flow_data_col='value',\n",
    "    map_schema='NWD',\n",
    "    streamflow_data_type='Real-Time Instantaneous'\n",
    "    )\n",
    "display(map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Current Flow Conditions Map for n-Day Daily Streamflow\n",
    "\n",
    "### Retrieve daily streamflow records for past n-days\n",
    "Let's download data from the Water Data APIs for the past 7 days and calculate a 7-day average. We will define the \"n\"-day in the beginning of this section. If instead we want to calculate a different n-day average, like a 14-day or 28-day, we would simply change the value of `n_days`. Also recall that we defined \"yesterday\" above, and will use it to download our data up to that date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your n-day period here.\n",
    "# Choose from 1, 7, 14, or 28 days\n",
    "n_days = 7\n",
    "\n",
    "seven_days_back = datetime.strftime(datetime.now(tz=ZoneInfo(\"US/Eastern\")) - timedelta(n_days), '%Y-%m-%d')\n",
    "\n",
    "past_dvs,_ = waterdata.get_daily(\n",
    "    monitoring_location_id=active_stream_gages['monitoring_location_id'].tolist(), \n",
    "    parameter_code='00060',\n",
    "    statistic_id='00003',\n",
    "    time=f\"{seven_days_back}/{yesterday}\",\n",
    "    skip_geometry=True\n",
    ")\n",
    "past_dvs = qaqc_usgs_data(past_dvs, 'value').set_index('time')\n",
    "past_dvs_n_d = pd.DataFrame()\n",
    "for StaID, new_df in past_dvs.groupby('monitoring_location_id'):\n",
    "    df = utils.rolling_average(new_df, 'value', f'{n_days}D').round(2)\n",
    "    past_dvs_n_d=pd.concat([past_dvs_n_d, df])\n",
    "past_dvs_n_d = past_dvs_n_d.dropna(subset=['value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate 7-day average streamflow and corresponding variable percentile thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_data_n_d = {}\n",
    "for StaID in tqdm(active_stream_gages['monitoring_location_id'].tolist(), disable=disable_tqdm):\n",
    "    if flow_data[StaID].shape[0] > 0:\n",
    "        flow_data_n_d[StaID] = utils.rolling_average(flow_data[StaID].set_index('time'), 'value', f'{n_days}D').round(2)\n",
    "    else:\n",
    "        print('No standard discharge data column found for site ' + StaID + ', skipping')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentile_values_n_d = {}\n",
    "for StaID in tqdm(active_stream_gages['monitoring_location_id'], disable=disable_tqdm, desc=\"Processing\"):\n",
    "    if flow_data[StaID].shape[0] > 0:\n",
    "        # Filter data down to only approved records to calculate statistics\n",
    "        df = utils.filter_approved_data(flow_data_n_d[StaID], 'approval_status')\n",
    "        # We are not defining the date column here, since it was switched to the index\n",
    "        # when calculating the rolling n-day average.\n",
    "        percentile_values_n_d[StaID] = percentiles.calculate_variable_percentile_thresholds_by_day(\n",
    "            df, \n",
    "            data_column_name='value',\n",
    "            percentiles=percentile_levels\n",
    "            )\n",
    "    else:\n",
    "        print('No standard discharge data column found for site ' + StaID + ', skipping')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorize streamflow based on calculated percentile values\n",
    "Calculate estimated streamflow percentile for the new data by interpolating against the previously calculated percentile threshold levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate percentiles\n",
    "df = pd.DataFrame()\n",
    "for StaID, site_df in past_dvs_n_d.groupby(\"monitoring_location_id\"):\n",
    "    if StaID in list(percentile_values_n_d.keys()):\n",
    "        if not percentile_values[StaID].isnull().all().all():\n",
    "            month_day = site_df.index.strftime('%m-%d')[0]\n",
    "            site_df['est_pct'] = percentiles.calculate_variable_percentile_from_value(\n",
    "            site_df['value'][0], percentile_values[StaID], month_day)\n",
    "            df = pd.concat([df, site_df])\n",
    "# categorize streamflow by the estimated streamflow percentiles\n",
    "df = utils.categorize_flows(df, 'est_pct', schema_name=\"NWD\")\n",
    "# keep only most recent 7-day average flow for plotting\n",
    "df = df[df.index.get_level_values('time') == yesterday]\n",
    "df = df.reset_index(level='time')\n",
    "# Prep Data for mapping by joining site information and flow data  \n",
    "gage_df = pd.merge(active_stream_gages, df, how=\"right\", on=\"monitoring_location_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Map of 7-Day Average Streamflow Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| fig-cap: Map showing most recent 7-day average streamflow and corresponding flow conditions\n",
    "\n",
    "map = create_gage_condition_map(\n",
    "    gage_df=gage_df,\n",
    "    flow_data_type='daily',\n",
    "    flow_data_col='value',\n",
    "    map_schema='NWD',\n",
    "    streamflow_data_type=f'Current {n_days}-Day Average'\n",
    "    )\n",
    "display(map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Drought Conditions Map for a Previous Day's Streamflow\n",
    "\n",
    "### Retrieve daily streamflow records from a past day\n",
    "Download data from the Water Data APIs and calculate corresponding streamflow percentiles for the given day's streamflow. Remember that we are comparing past days to the historical percentles calculated from the full streamflow record up to present. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "past_day = \"2023-05-30\"\n",
    "\n",
    "past_dvs,_ = waterdata.get_daily(\n",
    "    monitoring_location_id=active_stream_gages['monitoring_location_id'].tolist(),\n",
    "    parameter_code='00060',\n",
    "    statistic_id='00003',\n",
    "    time=past_day,\n",
    "    skip_geometry=True\n",
    "    )\n",
    "past_dvs = qaqc_usgs_data(past_dvs, 'value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorize streamflow based on calculated percentile values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate estimated streamflow percentile for the new data by interpolating against\n",
    "# the previously calculated percentile threshold levels\n",
    "df = pd.DataFrame()\n",
    "for StaID, site_df in past_dvs.groupby(by=\"monitoring_location_id\", group_keys=False):\n",
    "    if StaID in list(percentile_values.keys()):\n",
    "        if not percentile_values[StaID].isnull().all().all():\n",
    "            percentile_df = percentiles.calculate_multiple_variable_percentiles_from_values(\n",
    "            site_df,\n",
    "            data_column_name = 'value',\n",
    "            percentile_df = percentile_values[StaID],\n",
    "            date_column_name = 'time')\n",
    "            df = pd.concat([df, percentile_df])\n",
    "# categorize streamflow by the estimated streamflow percentiles\n",
    "df = utils.categorize_flows(df, 'est_pct', schema_name=\"WaterWatch_Drought\")\n",
    "df = df.reset_index(level='time')\n",
    "# Prep Data for mapping by joining site information and flow data  \n",
    "gage_df = pd.merge(active_stream_gages, df, how=\"right\", on=\"monitoring_location_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Map of Streamflow Drought Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| fig-cap: Map showing historical daily mean streamflow and corresponding flow conditions using a drought categorization schema\n",
    "map = create_gage_condition_map(\n",
    "    gage_df=gage_df,\n",
    "    flow_data_type='daily',\n",
    "    flow_data_col='value',\n",
    "    map_schema='WaterWatch_Drought',\n",
    "    streamflow_data_type='Daily Mean'\n",
    "    )\n",
    "display(map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Flood Conditions Map for a past Day's Streamflow\n",
    "This example uses fixed percentiles that are not calculated by  day of year, but instead across all days of the year together. Flow categories are therefore relative to absolute streamflow levels rather than what is normal for that day of the year.\n",
    "\n",
    "### Retrieve daily streamflow records from a past day\n",
    "Download data from the Water Data APIs and calculate corresponding fixed streamflow percentiles for the given day's streamflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "past_day = \"2023-07-10\"\n",
    "\n",
    "past_dvs,_ = waterdata.get_daily(\n",
    "    monitoring_location_id=active_stream_gages['monitoring_location_id'].tolist(),\n",
    "    parameter_code='00060',\n",
    "    statistic_id='00003',\n",
    "    time=past_day,\n",
    "    skip_geometry=True\n",
    "    )\n",
    "past_dvs = qaqc_usgs_data(past_dvs, 'value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_percentile_values = {}\n",
    "\n",
    "for StaID in tqdm(active_stream_gages['monitoring_location_id'], disable=disable_tqdm):\n",
    "    if flow_data[StaID].shape[0] > 0:\n",
    "        # Filter data down to only approved records to calculate statistics\n",
    "        df = utils.filter_approved_data(flow_data[StaID], 'approval_status')\n",
    "        if not df.empty:\n",
    "            fixed_percentile_values[StaID] = percentiles.calculate_fixed_percentile_thresholds(\n",
    "                df,\n",
    "                data_column_name='value',\n",
    "                date_column_name='time',\n",
    "                percentiles=percentile_levels\n",
    "                )\n",
    "        else:\n",
    "            print(StaID + ' has no approved data, skipping')\n",
    "    else:\n",
    "        print(StaID + ' does not have standard discharge data column, skipping')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorize streamflow based on calculated percentile values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate percentiles\n",
    "for StaID in past_dvs['monitoring_location_id'].unique().tolist():\n",
    "    if StaID in list(fixed_percentile_values.keys()):\n",
    "        past_dvs.loc[(past_dvs['monitoring_location_id'] == StaID) & (past_dvs['time'] == past_day), 'est_pct'] = percentiles.calculate_fixed_percentile_from_value(\n",
    "            past_dvs.loc[(past_dvs['monitoring_location_id'] == StaID) & (past_dvs['time'] == past_day), 'value'],\n",
    "            fixed_percentile_values[StaID]\n",
    "        )\n",
    "# categorize streamflow by the estimated streamflow percentiles\n",
    "df = utils.categorize_flows(past_dvs, 'est_pct', schema_name=\"WaterWatch_Flood\")\n",
    "# Prep Data for mapping by joining site information and flow data  \n",
    "gage_df = pd.merge(active_stream_gages, df, how=\"right\", on=\"monitoring_location_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Map of Streamflow High-Flow Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| fig-cap: Map showing historical daily mean streamflow and corresponding flow conditions using a high-flow categorization schema\n",
    "map = create_gage_condition_map(\n",
    "    gage_df=gage_df,\n",
    "    flow_data_type='daily',\n",
    "    flow_data_col='value',\n",
    "    map_schema='WaterWatch_Flood',\n",
    "    streamflow_data_type='Daily Mean'\n",
    "    )\n",
    "display(map)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,qmd"
  },
  "kernelspec": {
   "display_name": "hyswap-doc-update",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
