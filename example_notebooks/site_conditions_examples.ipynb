{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Visualization of Streamflow Conditions at Streamgages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides a demonstration of the use of [hyswap](https://doi-usgs.github.io/hyswap/) python package for calculating streamflow percentiles and then visualizing streamflow conditions at multiple streamflow gages. \n",
    "\n",
    "This example notebook relies on use of the [dataretrieval](https://github.com/DOI-USGS/dataRetrieval) package for downloading streamflow information from USGS NWIS as well as the [geopandas](https://geopandas.org/) package for mapping functionality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run commented lines below to install geopandas and mapping dependencies from within the notebook\n",
    "#import sys\n",
    "#!{sys.executable} -m pip install geopandas folium mapclassify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataretrieval import nwis\n",
    "import hyswap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from zoneinfo import ZoneInfo\n",
    "\n",
    "from tqdm import tqdm # used for progress bar indicators\n",
    "import geopandas # has dependencies of folium and mapclassify to create maps within this notebook\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # ignore warnings from dataretrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** The `tqdm` package is used in for-loops in this notebook to show a data download progress bar, which may be informative to the user. The specification below (`disable_tdqm`) determines whether this progress bar is displayed when the notebook renders. It is set to `True` when rendering the notebook in the `hyswap` GitHub documentation site. To see the progress bars in this notebook, set `disable_tqdm=False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disable_tqdm=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Helper Functions\n",
    "The `hyswap` package provides functionality for calculating non-interpretive streamflow statistics but does not provide functionality for correcting invalid data or geospatial capabilities for mapping. Here we setup some simple helper functions we can re-use throughout the notebook to QAQC data and create maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data QAQC function for provisional NWIS data\n",
    "def qaqc_nwis_data(df, data_col):\n",
    "    #replace invalid -999999 values with NA\n",
    "    df[data_col] = df[data_col].replace(-999999, np.nan)\n",
    "    # add any additional QAQC steps needed\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gage_condition_map(gage_df, flow_data_col, map_schema, streamflow_data_type):\n",
    "        # Format date and set to str type for use in map tooltips\n",
    "        if flow_data_col == '00060':\n",
    "                gage_df['Date'] = gage_df['datetime'].dt.strftime('%Y-%m-%d %H:%M')\n",
    "        elif flow_data_col == '00060_Mean':\n",
    "                gage_df['Date'] = gage_df['datetime'].dt.strftime('%Y-%m-%d')\n",
    "        gage_df = gage_df.drop('datetime', axis=1)\n",
    "        # create colormap for map from hyswap schema\n",
    "        schema = hyswap.utils.retrieve_schema(map_schema)\n",
    "        flow_cond_cmap = schema['colors']\n",
    "        if 'low_color' in schema:\n",
    "                flow_cond_cmap = [schema['low_color']] + flow_cond_cmap\n",
    "        if 'high_color' in schema:\n",
    "                flow_cond_cmap = flow_cond_cmap + [schema['high_color']]\n",
    "        # if creating a drought map, set handling of non-drought flows\n",
    "        if map_schema in ['WaterWatch_Drought', 'NIDIS_Drought']:\n",
    "                gage_df['flow_cat'] = gage_df['flow_cat'].cat.add_categories('Other')\n",
    "                gage_df.loc[gage_df['flow_cat'].isnull(), 'flow_cat'] = 'Other'\n",
    "                flow_cond_cmap = flow_cond_cmap + ['#e3e0ca'] # light taupe\n",
    "        # set NA values to \"Not Ranked\" category\n",
    "        gage_df['flow_cat'] = gage_df['flow_cat'].cat.add_categories('Not Ranked')\n",
    "        gage_df.loc[gage_df['est_pct'].isna(), 'flow_cat'] = 'Not Ranked'\n",
    "        flow_cond_cmap = flow_cond_cmap + ['#d3d3d3'] # light grey\n",
    "        # renaming columns with user friendly names for map\n",
    "        gage_df = gage_df.rename(columns={flow_data_col:'Discharge (cfs)',\n",
    "                                                'est_pct':'Estimated Percentile',\n",
    "                                                'site_no':'USGS Gage ID',\n",
    "                                                'station_nm':'Streamgage Name',\n",
    "                                                'flow_cat':'Streamflow Category'})\n",
    "        # convert dataframe to geopandas GeoDataFrame\n",
    "        gage_df = geopandas.GeoDataFrame(gage_df, \n",
    "                             geometry=geopandas.points_from_xy(gage_df.dec_long_va,\n",
    "                                                               gage_df.dec_lat_va), \n",
    "                             crs=\"EPSG:4326\").to_crs(\"EPSG:5070\")\n",
    "        # Create map\n",
    "        m = gage_df.explore(column=\"Streamflow Category\",\n",
    "                                cmap=flow_cond_cmap,\n",
    "                                tooltip=[\"USGS Gage ID\", \"Streamgage Name\", \"Streamflow Category\", \"Discharge (cfs)\", \"Estimated Percentile\", \"Date\"],\n",
    "                                tiles=\"CartoDB Positron\",\n",
    "                                marker_kwds=dict(radius=5),\n",
    "                                legend_kwds=dict(caption=streamflow_data_type + '<br> Streamflow  Category'))\n",
    "        return m #returns a folium map object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Downloading and Processing\n",
    "Utilize an example state to select streamgages for generating various flow condition maps. Certain past days selected in the notebook are relevant to using the state of Vermont (VT) as an example, but the notebook can be run for any state.\n",
    "\n",
    "### Find all stream sites active in the last year within a State\n",
    "Limit the search to streamgages that have also been operational prior to approximately 10 years ago as a minimum of 10 years of flow records should be available for calculating streamflow percentiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| tbl-cap: List of streamgage sites active within the last week\n",
    "state = 'VT'\n",
    "# Query NWIS for what streamgage sites were active within the last week\n",
    "active_nwis_sites, _ = nwis.what_sites(stateCd=state, parameterCd='00060', period=\"P1W\", siteType='ST')\n",
    "# Find gages present in both of the above queries to get a list of gages that were\n",
    "#  recently active that also have records from more than 10 years ago\n",
    "sites = active_nwis_sites#[active_nwis_sites['site_no'].isin(nwis_sites['site_no'])]\n",
    "display(sites)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve Streamflow Data from NWIS\n",
    "For the sites identified above, download all historical daily streamflow data (1900 through 2023 Water Years). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a python dictionary of dataframes by site id number\n",
    "flow_data = {}\n",
    "\n",
    "for StaID in tqdm(sites['site_no'], disable=disable_tqdm, desc=\"Downloading NWIS Flow Data for Sites\"):\n",
    "    flow_data[StaID] = nwis.get_record(sites=StaID, parameterCd='00060', start=\"1900-01-01\", end=\"2023-10-01\", service='dv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Variable Streamflow Percentile Thresholds\n",
    "For the sites identified above, calculate streamflow percentile thresholds at 0, 1, 5, 10, ... , 90, 95, 99, 100 percentiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define what percentile levels (thresholds) that we want to calculate.\n",
    "# Intervals of 5 or less are recommended to have sufficient levels to interpolate between in later calculations. \n",
    "# Note that 0 and 100 percentile levels are ignored. Refer to min and max values returned instead\n",
    "percentile_levels = np.concatenate((np.array([1]), np.arange(5,96,5), np.array([99])), axis=0)\n",
    "print(percentile_levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentile_values = {}\n",
    "for StaID in tqdm(sites['site_no'], disable=disable_tqdm, desc=\"Processing Sites\"):\n",
    "    if '00060_Mean' in flow_data[StaID].columns:\n",
    "        # Filter data as only approved data in NWIS should be used to calculate statistics\n",
    "        df = hyswap.utils.filter_approved_data(flow_data[StaID], '00060_Mean_cd')\n",
    "        percentile_values[StaID] = hyswap.percentiles.calculate_variable_percentile_thresholds_by_day(\n",
    "            df, '00060_Mean', percentiles=percentile_levels)\n",
    "    else:\n",
    "        print('No standard discharge data column found for site ' + StaID + ', skipping')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| tbl-cap: Sample of calcualted variable streamflow percentile thresholds for first site in list\n",
    "# View percentile thresholds for the first site\n",
    "display(percentile_values[list(percentile_values.keys())[0]].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Current Flow Conditions Map for Daily Mean Streamflow\n",
    "\n",
    "### Retrieve most recent (yesterday) daily mean streamflow\n",
    "Download data from NWIS and calculate corresponding streamflow percentile for the most recent daily mean discharge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yesterday = datetime.strftime(datetime.now(tz=ZoneInfo(\"US/Eastern\")) - timedelta(1), '%Y-%m-%d')\n",
    "recent_dvs = nwis.get_record(sites=sites['site_no'].tolist(), parameterCd='00060', start=yesterday, end=yesterday, service='dv')\n",
    "recent_dvs = qaqc_nwis_data(recent_dvs, '00060_Mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorize streamflow based on calculated percentile values\n",
    "Calculate estimated streamflow percentile for the new data by interpolating against the previously calculated percentile threshold levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate percentiles\n",
    "df = pd.DataFrame()\n",
    "for StaID, site_df in recent_dvs.groupby(level=\"site_no\", group_keys=False):\n",
    "    if StaID in list(percentile_values.keys()):\n",
    "        if not percentile_values[StaID].isnull().all().all():\n",
    "            percentiles = hyswap.percentiles.calculate_multiple_variable_percentiles_from_values(\n",
    "            site_df,'00060_Mean', percentile_values[StaID])\n",
    "            df = pd.concat([df, percentiles])\n",
    "# categorize streamflow by the estimated streamflow percentiles\n",
    "df = hyswap.utils.categorize_flows(df, 'est_pct', schema_name=\"NWD\")\n",
    "df = df.reset_index(level='datetime')\n",
    "# Prep Data for mapping by joining site information and flow data  \n",
    "gage_df = pd.merge(sites, df, how=\"right\", on=\"site_no\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Map of Streamflow Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| fig-cap: Map showing most recent daily mean streamflow and corresponding flow conditions\n",
    "map = create_gage_condition_map(gage_df, '00060_Mean', 'NWD', 'Current Daily Mean')\n",
    "display(map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Map of Streamflow Conditions using Alternative Categorization Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| fig-cap: Map showing most recent daily mean streamflow and corresponding flow conditions using a brown-blue schema\n",
    "\n",
    "# Prep Data for mapping by joining site information and flow data  \n",
    "map = create_gage_condition_map(gage_df, '00060_Mean', 'WaterWatch_BrownBlue', 'Current Daily Mean')\n",
    "display(map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a \"Real-Time\" Flow Conditions Map for Instantaneous Streamflow\n",
    "\n",
    "### Retrieve most recent instantaneous streamflow records\n",
    "Download data from NWIS and calculate corresponding streamflow percentile for the most recent instantaneous discharge measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recent_ivs = nwis.get_record(sites=sites['site_no'].tolist(), parameterCd='00060', service='iv')\n",
    "recent_ivs = qaqc_nwis_data(recent_ivs, '00060')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorize streamflow based on calculated percentile values\n",
    "Calculate estimated streamflow percentile for the new instantaneous data by interpolating against the previously calculated percentile threshold levels from daily streamflow records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate percentiles\n",
    "df = pd.DataFrame()\n",
    "for StaID, site_df in recent_ivs.groupby(level=\"site_no\", group_keys=False):\n",
    "    if StaID in list(percentile_values.keys()):\n",
    "        if not percentile_values[StaID].isnull().all().all():\n",
    "            percentiles = hyswap.percentiles.calculate_multiple_variable_percentiles_from_values(\n",
    "            site_df,'00060', percentile_values[StaID])\n",
    "            df = pd.concat([df, percentiles])\n",
    "# categorize streamflow by the estimated streamflow percentiles\n",
    "df = hyswap.utils.categorize_flows(df, 'est_pct', schema_name=\"NWD\")\n",
    "df = df.tz_convert(tz='US/Eastern')\n",
    "df = df.reset_index(level='datetime')\n",
    "# Prep Data for mapping by joining site information and flow data  \n",
    "gage_df = pd.merge(sites, df, how=\"right\", on=\"site_no\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Map of Real-Time Streamflow Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| fig-cap: Map showing most real-time streamflow conditions\n",
    "\n",
    "map = create_gage_condition_map(gage_df, '00060', 'NWD', 'Real-Time Instantaneous')\n",
    "display(map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Current Flow Conditions Map for n-Day Daily Streamflow\n",
    "\n",
    "### Retrieve daily streamflow records for past 7 days\n",
    "Download data from NWIS and calculate corresponding streamflow percentiles for each day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "past_dvs = nwis.get_record(\n",
    "    sites=sites['site_no'].tolist(), \n",
    "    parameterCd='00060',\n",
    "    start=datetime.strftime(datetime.now(tz=ZoneInfo(\"US/Eastern\")) - timedelta(7), '%Y-%m-%d'),\n",
    "    end=yesterday,\n",
    "    service='dv'\n",
    ")\n",
    "past_dvs = qaqc_nwis_data(past_dvs, '00060_Mean')\n",
    "past_dvs_7d = past_dvs.copy()\n",
    "for StaID, new_df in past_dvs.groupby(level=0):\n",
    "    past_dvs_7d.loc[StaID] = hyswap.utils.rolling_average(new_df, '00060_Mean', 7).round(2)\n",
    "\n",
    "past_dvs_7d = past_dvs_7d.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate 7-day average streamflow and corresponding variable percentile thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_data_7d = {}\n",
    "for StaID in tqdm(sites['site_no'], disable=disable_tqdm):\n",
    "    if '00060_Mean' in flow_data[StaID].columns:\n",
    "        flow_data_7d[StaID] = hyswap.utils.rolling_average(flow_data[StaID], '00060_Mean', 7).round(2)\n",
    "    else:\n",
    "        print('No standard discharge data column found for site ' + StaID + ', skipping')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentile_values_7d = {}\n",
    "for StaID in tqdm(sites['site_no'], disable=disable_tqdm, desc=\"Processing\"):\n",
    "    if '00060_Mean' in flow_data[StaID].columns:\n",
    "        # Filter data as only approved data in NWIS should be used to calculate statistics\n",
    "        df = hyswap.utils.filter_approved_data(flow_data_7d[StaID], '00060_Mean_cd')\n",
    "        percentile_values_7d[StaID] = hyswap.percentiles.calculate_variable_percentile_thresholds_by_day(\n",
    "            df, '00060_Mean', percentiles=percentile_levels)\n",
    "    else:\n",
    "        print('No standard discharge data column found for site ' + StaID + ', skipping')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorize streamflow based on calculated percentile values\n",
    "Calculate estimated streamflow percentile for the new data by interpolating against the previously calculated percentile threshold levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate percentiles\n",
    "df = pd.DataFrame()\n",
    "for StaID, site_df in past_dvs_7d.groupby(level=\"site_no\", group_keys=False):\n",
    "    if StaID in list(percentile_values_7d.keys()):\n",
    "        if not percentile_values[StaID].isnull().all().all():\n",
    "            percentiles = hyswap.percentiles.calculate_multiple_variable_percentiles_from_values(\n",
    "            site_df,'00060_Mean', percentile_values[StaID])\n",
    "            df = pd.concat([df, percentiles])\n",
    "# categorize streamflow by the estimated streamflow percentiles\n",
    "df = hyswap.utils.categorize_flows(df, 'est_pct', schema_name=\"NWD\")\n",
    "# keep only most recent 7-day average flow for plotting\n",
    "df = df[df.index.get_level_values('datetime') == yesterday]\n",
    "df = df.reset_index(level='datetime')\n",
    "# Prep Data for mapping by joining site information and flow data  \n",
    "gage_df = pd.merge(sites, df, how=\"right\", on=\"site_no\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Map of 7-Day Average Streamflow Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| fig-cap: Map showing most recent 7-day average streamflow and corresponding flow conditions\n",
    "\n",
    "map = create_gage_condition_map(gage_df, '00060_Mean', 'NWD', 'Current 7-Day Average')\n",
    "display(map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Drought Conditions Map for a Previous Day's Streamflow\n",
    "\n",
    "### Retrieve daily streamflow records from a past day\n",
    "Download data from NWIS and calculate corresponding streamflow percentiles for the given day's streamflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "past_day = \"2023-05-30\"\n",
    "\n",
    "past_dvs = nwis.get_record(sites=sites['site_no'].tolist(),\n",
    "                              parameterCd='00060',\n",
    "                              start=past_day,\n",
    "                              end=past_day,\n",
    "                              service='dv')\n",
    "past_dvs = qaqc_nwis_data(past_dvs, '00060_Mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorize streamflow based on calculated percentile values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate estimated streamflow percentile for the new data by interpolating against\n",
    "# the previously calculated percentile threshold levels\n",
    "df = pd.DataFrame()\n",
    "for StaID, site_df in past_dvs.groupby(level=\"site_no\", group_keys=False):\n",
    "    if StaID in list(percentile_values.keys()):\n",
    "        if not percentile_values[StaID].isnull().all().all():\n",
    "            percentiles = hyswap.percentiles.calculate_multiple_variable_percentiles_from_values(\n",
    "            site_df,'00060_Mean', percentile_values[StaID])\n",
    "            df = pd.concat([df, percentiles])\n",
    "# categorize streamflow by the estimated streamflow percentiles\n",
    "df = hyswap.utils.categorize_flows(df, 'est_pct', schema_name=\"WaterWatch_Drought\")\n",
    "df = df.reset_index(level='datetime')\n",
    "# Prep Data for mapping by joining site information and flow data  \n",
    "gage_df = pd.merge(sites, df, how=\"right\", on=\"site_no\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Map of Streamflow Drought Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| fig-cap: Map showing historical daily mean streamflow and corresponding flow conditions using a drought categorization schema\n",
    "map = create_gage_condition_map(gage_df, '00060_Mean', 'WaterWatch_Drought', 'Daily Mean')\n",
    "display(map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Flood Conditions Map for a past Day's Streamflow\n",
    "This example uses fixed percentiles that are not calculated by  day of year, but instead across all days of the year together. Flow categories are therefore relative to absolute streamflow levels rather than what is normal for that day of the year.\n",
    "\n",
    "### Retrieve daily streamflow records from a past day\n",
    "Download data from NWIS and calculate corresponding fixed streamflow percentiles for the given day's streamflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "past_day = \"2023-07-10\"\n",
    "\n",
    "past_dvs = nwis.get_record(sites=sites['site_no'].tolist(),\n",
    "                           parameterCd='00060',\n",
    "                           start=past_day,\n",
    "                           end=past_day,\n",
    "                           service='dv')\n",
    "past_dvs = qaqc_nwis_data(past_dvs, '00060_Mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_percentile_values = {}\n",
    "\n",
    "for StaID in tqdm(sites['site_no'], disable=disable_tqdm):\n",
    "    if '00060_Mean' in flow_data[StaID].columns:\n",
    "        # Filter data as only approved data in NWIS should be used to calculate statistics\n",
    "        df = hyswap.utils.filter_approved_data(flow_data[StaID], '00060_Mean_cd')\n",
    "        if not df.empty:\n",
    "            fixed_percentile_values[StaID] = hyswap.percentiles.calculate_fixed_percentile_thresholds(\n",
    "                df['00060_Mean'], percentiles=percentile_levels)\n",
    "        else:\n",
    "            print(StaID + ' has no approved data, skipping')\n",
    "    else:\n",
    "        print(StaID + ' does not have standard discharge data column, skipping')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorize streamflow based on calculated percentile values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate percentiles\n",
    "for StaID in past_dvs.index.get_level_values(0):\n",
    "    if StaID in list(fixed_percentile_values.keys()):\n",
    "        past_dvs.at[(StaID, past_day), 'est_pct'] = hyswap.percentiles.calculate_fixed_percentile_from_value(\n",
    "            past_dvs.at[(StaID, past_day), '00060_Mean'], fixed_percentile_values[StaID])\n",
    "# categorize streamflow by the estimated streamflow percentiles\n",
    "df = hyswap.utils.categorize_flows(past_dvs, 'est_pct', schema_name=\"WaterWatch_Flood\")\n",
    "df = df.reset_index(level='datetime')\n",
    "# Prep Data for mapping by joining site information and flow data  \n",
    "gage_df = pd.merge(sites, df, how=\"right\", on=\"site_no\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Map of Streamflow High-Flow Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| fig-cap: Map showing historical daily mean streamflow and corresponding flow conditions using a high-flow categorization schema\n",
    "map = create_gage_condition_map(gage_df, '00060_Mean', 'WaterWatch_Flood', 'Daily Mean')\n",
    "display(map)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,qmd"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
