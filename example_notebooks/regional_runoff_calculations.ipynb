{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Using hyswap to estimate runoff for one and multiple HUC08s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to use the [hyswap](https://doi-usgs.github.io/hyswap/) python package to estimate runoff over 10 water years (2013-2023) for a set of hydrologic units using streamflow measured at gages that overlap with the hydrologic units of interest. \n",
    "\n",
    "This example notebook relies on use of the [dataretrieval](https://github.com/DOI-USGS/dataRetrieval) package for downloading streamflow information from USGS NWIS.\n",
    "\n",
    "Hydrologic units will be referred to as \"hucs\" and the drainage area captured by a streamflow gage will be referred to as a \"basin\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataretrieval\n",
    "import hyswap\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches\n",
    "from pynhd import WaterData\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # ignore warnings from dataretrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in huc-basin intersection table\n",
    "\n",
    "The huc-basin intersection dataset is created using shapefiles for hucs and site drainage basins, and is the output of the [hyswap geospatial data assembly repository](https://code.usgs.gov/water/computational-tools/surface-water-work/hyswap-geospatial-data-assembly) . For each huc-basin intersection, it contains the proportion of the huc's area in the basin, and the proportion of the basin's area in the huc. You can find this file in the 'example_data' folder within the 'example_notebooks' folder in the `hyswap` repository. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| tbl-cap: The top rows of the intersection table created by the hyswap geospatial data assembly repository\n",
    "# This example initially reads in the entire huc_basin_intersection table.\n",
    "intersection_table_full = pd.read_csv('example_data/huc_props_tbl_conus.csv', \n",
    "                             converters = {0:str,1:str,2:str}\n",
    "                             )\n",
    "\n",
    "# drop first col that is the index from the csv. \n",
    "intersection_table_full.drop(columns=intersection_table_full.columns[0],\n",
    "                    axis=1,\n",
    "                    inplace=True\n",
    ")\n",
    "# view\n",
    "intersection_table_full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select watershed to estimate runoff\n",
    "This example focuses on a bounding box of HUC08's in Montana and Idaho. We will first filter to one of the hucs to show how to estimate runoff for a single huc, but later on we will estimate runoff for all hucs in the dataset. We will also establish the start and end dates over which we'd like to estimate runoff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "huc_shapes = WaterData('huc08').bybox([-115.065380, 45.947037, -112.692334, 47.572536])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| tbl-cap: The first few rows of the geopandas dataframe from `pynhd`\n",
    "huc_shapes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| fig-cap: 'A map of the single HUC08, 17010209'\n",
    "single_huc = huc_shapes['huc8'][9]\n",
    "\n",
    "start_date = '2012-10-01'\n",
    "end_date = '2023-09-30'\n",
    "\n",
    "huc_shapes[huc_shapes['huc8'] == single_huc].explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wanted to estimate runoff for one huc, we would first identify which basins intersect the huc using the `identify_sites_from_geom_intersection` function. From this list of basins, we would then download their corresponding gage streamflow data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull basin site ids from selected huc8 geom using the hyswap runoff identify sites from geom intersection function\n",
    "basins_overlap_single_huc = hyswap.runoff.identify_sites_from_geom_intersection(geom_id = single_huc,\n",
    "                                   geom_intersection_df = intersection_table_full,\n",
    "                                   geom_id_col='huc_id',\n",
    "                                   site_col='da_site_no',\n",
    "                                   prop_geom_in_basin_col='prop_huc_in_basin',\n",
    "                                   prop_basin_in_geom_col='prop_basin_in_huc'\n",
    "                                   )\n",
    "\n",
    "# output should be long list of sites ids. These are all the site_ids within the selected huc8 polygon\n",
    "num_sites = len(basins_overlap_single_huc)\n",
    "print(f'There are {num_sites} gaged basins that overlap this huc.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom function for grabbing gage flow data from `dataretrieval` and converting it to runoff    \n",
    "To estimate runoff for a huc, we need to create a dictionary of runoff data, where each key corresponds to a site id for a basin, and the item is a dataframe with a datetime index and runoff values for that site in a 'runoff' column. The function below leverages `dataretrieval` to pull streamflow data for a set of input sites over a specified date range, and then uses `hyswap`'s `streamflow_to_runoff` function in the `runoff` module to estimate area-based runoff using site drainage areas. It produces runoff values in millimeters per day. Note that this function can take some time, depending upon the size/number of queries. Additionally, it is not unusual for many sites to return no data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_nwis_runoff_data(sites,\n",
    "    start_date,\n",
    "    end_date):\n",
    "    print(\"Pulling site streamflow data and converting it to runoff. This may take some time...\")\n",
    "    # first, pull site info \n",
    "    info_df, _ = dataretrieval.nwis.get_info(sites=sites)\n",
    "    # convert drainage area from sq mi to sq km\n",
    "    info_df['da'] = info_df['drain_area_va'] * 2.58998811\n",
    "    # info_df = info_df[['da', 'site_no']]\n",
    "    # get streamflow data between start and end date\n",
    "    dv_df = dataretrieval.nwis.get_record(\n",
    "        sites=sites, parameterCd='00060',\n",
    "        start=start_date, end=end_date,\n",
    "        multi_index=False,\n",
    "        service='dv'\n",
    "        )\n",
    "    df_nwis_ro_data = pd.DataFrame()\n",
    "\n",
    "    if not dv_df.empty:\n",
    "        # get site ids from dv_df and create empty\n",
    "        # df to hold site runoff data\n",
    "        siteids = dv_df['site_no'].unique().tolist()\n",
    "\n",
    "        # Loop through sites retrieved from nwis and estimate\n",
    "        # runoff using hyswap function\n",
    "        for site in siteids:\n",
    "            ro_df = dv_df[dv_df['site_no']==site]\n",
    "            da = info_df.loc[info_df['site_no']==site]['da']\n",
    "            ro_df = hyswap.runoff.streamflow_to_runoff(ro_df, '00060_Mean', da, frequency='daily')\n",
    "            df_nwis_ro_data = pd.concat([df_nwis_ro_data, ro_df])\n",
    "        # print proportion of sites with data\n",
    "        prop = len(siteids)/len(sites)\n",
    "        print(f'\\nProp of successful nwis queries from list of sites:\\n {prop}')\n",
    "    else:\n",
    "        print(f\"No site data available, returning empty dataframe\")\n",
    "    \n",
    "    return(df_nwis_ro_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download gage data\n",
    "Let's try using `query_nwis_runoff_data` to download streamflow data and convert it to runoff (in mm/day) from 2013-2023 for our selected huc '07090001'. Note that not all gage sites listed in `basins_overlap_single_huc` will necessarily have data for the date range specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nwis_ro_data = query_nwis_runoff_data(basins_overlap_single_huc,\n",
    "start_date = start_date,\n",
    "end_date = end_date)\n",
    "display(df_nwis_ro_data[df_nwis_ro_data['site_no'] == '06078500'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate runoff for the huc\n",
    "With daily basin runoff data in hand, we are ready to estimate runoff for the huc in mm/day. Please reference `hyswap`'s Calculations page to understand how runoff is estimated using this function. Briefly, this function identifies basins contained within the huc and basins that contain the huc that have runoff data for the entire time period in the dataset. It then estimates a weighted mean runoff value for each day using applicable and available basins. If `clip_downstream_basins` is set to True, the function only uses the smallest basin that contains the huc and disregards downstream gages that represent larger basins that contain the huc. This example will loop through each water year and estimate runoff using basins with complete records for each water year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get water year in dataset so can loop by water year to estimate runoff\n",
    "df_nwis_ro_data['water_year'] = df_nwis_ro_data.index.year\n",
    "df_nwis_ro_data['water_year'][df_nwis_ro_data.index.month >= 10] = df_nwis_ro_data['water_year'] + 1\n",
    "        \n",
    "# create df to hold estimate results\n",
    "results = pd.DataFrame()\n",
    "        \n",
    "    # loop through each water year\n",
    "for year, df_year in df_nwis_ro_data.groupby(df_nwis_ro_data.water_year):\n",
    "    df_nwis_ro_data_sub = df_nwis_ro_data[df_nwis_ro_data['water_year'] == year]\n",
    "\n",
    "                # estimate runoff for each water year of data\n",
    "    single_huc_runoff = hyswap.calculate_geometric_runoff(\n",
    "        geom_id=single_huc,\n",
    "        runoff_df=df_nwis_ro_data_sub,\n",
    "        geom_intersection_df=intersection_table_full,\n",
    "        site_col='da_site_no',\n",
    "        geom_id_col='huc_id',\n",
    "        prop_geom_in_basin_col='prop_huc_in_basin',\n",
    "        prop_basin_in_geom_col='prop_basin_in_huc',\n",
    "        percentage=False,\n",
    "        clip_downstream_basins=False,\n",
    "        full_overlap_threshold=0.98\n",
    "        )\n",
    "            \n",
    "                # concatenate with previous years runoffs\n",
    "    results = pd.concat([results, single_huc_runoff])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a quick look at the estimated runoff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| fig-cap: A runoff hydrograph for huc 17010209 using the `hyswap.plot_hydrograph` function\n",
    "hyswap.plot_hydrograph(\n",
    "    results,\n",
    "    data_col='estimated_runoff',\n",
    "    title=f'Estimated Runoff for HUC {single_huc}',\n",
    "    yscale='linear',\n",
    "    ylab='Runoff (mm)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate runoff for all hucs\n",
    "Now, we will estimate runoff for all of the hucs in the region selected. First, we'll identify the sites with drainage basins that intersect the seven hucs. Next, we'll need to use our custom function to download flow data and estimate runoff for each basin. Finally, we can leverage `hyswap`'s `calculate_multiple_geometric_runoff`, which loops through a list of hucs, finds their intersecting gage basins, and estimates runoff for each day in the dataset. Note that by setting the `clip_downstream_basins` argument to True, the function is only considering basins within each HUC08 and the smallest basin containing each HUC08 in the runoff estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_site_ids = []\n",
    "\n",
    "# loop through to get all sites (identify_sites_from_geom_intersection() cannot accept multiple geom_ids) \n",
    "for huc in huc_shapes['huc8']:\n",
    "    sites = hyswap.runoff.identify_sites_from_geom_intersection(\n",
    "        geom_id = huc,\n",
    "        geom_intersection_df = intersection_table_full,\n",
    "        geom_id_col='huc_id',\n",
    "        site_col='da_site_no',\n",
    "        prop_geom_in_basin_col='prop_huc_in_basin',\n",
    "        prop_basin_in_geom_col='prop_basin_in_huc'\n",
    "        )\n",
    "    \n",
    "    list_site_ids.append(sites)\n",
    "\n",
    "# join list of lists, as for loop above separates out the list of dfs \n",
    "all_site_ids = sum(list_site_ids,[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab basin data using the all_site_ids list\n",
    "df_nwis_ro_data = query_nwis_runoff_data(all_site_ids, start_date=start_date,\n",
    "end_date=end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# get water year in dataset so can loop by water year to estimate runoff\n",
    "df_nwis_ro_data['water_year'] = df_nwis_ro_data.index.year\n",
    "df_nwis_ro_data['water_year'][df_nwis_ro_data.index.month >= 10] = df_nwis_ro_data['water_year'] + 1\n",
    "        \n",
    "# create df to hold estimate results\n",
    "results = pd.DataFrame()\n",
    "        \n",
    "# loop through each water year\n",
    "for year, df_year in df_nwis_ro_data.groupby(df_nwis_ro_data.water_year):\n",
    "    # subset data to water year\n",
    "    df_nwis_ro_data_sub = df_nwis_ro_data[df_nwis_ro_data['water_year'] == year]\n",
    "    \n",
    "    multiple_huc_runoff = hyswap.runoff.calculate_multiple_geometric_runoff(\n",
    "        geom_id_list = huc_shapes['huc8'],\n",
    "        runoff_df = df_nwis_ro_data,\n",
    "        geom_intersection_df=intersection_table_full,\n",
    "        site_col='da_site_no',\n",
    "        geom_id_col='huc_id',\n",
    "        prop_geom_in_basin_col= 'prop_huc_in_basin',\n",
    "        prop_basin_in_geom_col='prop_basin_in_huc',\n",
    "        percentage=False,\n",
    "        clip_downstream_basins=True,\n",
    "        full_overlap_threshold=0.98\n",
    "        )\n",
    "    results = pd.concat([results, multiple_huc_runoff])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like our single huc runoff calculation, we can take a look at the estimated runoff across multiple hucs. Because there are 16 HUCs in this dataset, we will only plot a subset below using the `pivot_table` function from `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| fig-cap: A multiple runoff hydrograph for all hucs pulled from `pynhd` in this example\n",
    "# Plot \n",
    "results_plot = results.pivot_table(index=results.index, columns='geom_id', values='estimated_runoff')\n",
    "ax = results_plot.iloc[:, 10:14].plot()\n",
    "ax.set_ylabel(\"Runoff (mm)\")\n",
    "ax.legend(title='HUC ID')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping the results of the runoff calculation\n",
    "In this step of the analysis, we will estimate variable percentiles by day for each huc, and then use those percentiles to estimate a percentile for a new estimated runoff value. We will then plot these percentiles in a map of the hucs.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "huc_ids = results['geom_id'].unique()\n",
    "\n",
    "percentile_results = {}\n",
    "\n",
    "for huc_id in huc_ids:\n",
    "    results_sub = results[results['geom_id'] == huc_id]\n",
    "    results_sub.sort_index(inplace=True)\n",
    "    percentiles = hyswap.calculate_variable_percentile_thresholds_by_day(results_sub,\n",
    "                                                                         data_column_name='estimated_runoff')\n",
    "    percentile_results[huc_id] = percentiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will pull a new set of gage streamflow data for the first day of the next water year, and estimate runoff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "start_date = '2023-10-01'\n",
    "end_date = '2023-10-01'\n",
    "# grab basin data using the all_site_ids list\n",
    "df_nwis_ro_data_new = query_nwis_runoff_data(all_site_ids, start_date=start_date, end_date=end_date)\n",
    "\n",
    "multiple_huc_runoff_new = hyswap.runoff.calculate_multiple_geometric_runoff(\n",
    "    geom_id_list = huc_shapes['huc8'],\n",
    "    runoff_df = df_nwis_ro_data_new,\n",
    "    geom_intersection_df=intersection_table_full,\n",
    "    site_col='da_site_no',\n",
    "    geom_id_col='huc_id',\n",
    "    prop_geom_in_basin_col= 'prop_huc_in_basin',\n",
    "    prop_basin_in_geom_col='prop_basin_in_huc',\n",
    "    percentage=False,\n",
    "    clip_downstream_basins=True,\n",
    "    full_overlap_threshold=0.98\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With runoff in hand, we can then calculate the percentile for this date for each HUC08, based on the percentiles we calculated for the previous 5-year period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate estimated streamflow percentile for the new data by interpolating against\n",
    "# the previously calculated percentile threshold levels\n",
    "huc_perc_df = pd.DataFrame()\n",
    "\n",
    "for huc, huc_df in multiple_huc_runoff_new.groupby('geom_id', group_keys=False):\n",
    "    huc_perc_df = pd.concat([huc_perc_df, hyswap.percentiles.calculate_multiple_variable_percentiles_from_values(\n",
    "            huc_df,'estimated_runoff', percentile_results[huc])])\n",
    "# categorize streamflow by the estimated streamflow percentiles\n",
    "huc_perc_df = hyswap.utils.categorize_flows(huc_perc_df, 'est_pct', schema_name=\"NWD\")\n",
    "huc_perc_df = huc_perc_df.reset_index(level='datetime')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, create an interactive map showing HUC08 runoff percentiles for October 1, 2023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| fig-cap: 'HUC08 colors correspond to the runoff percentiles for 10-01-2023 flow based on 5 years of estimated runoff data at the HUC08 scale, derived from gage basin flow data.'\n",
    "# merge percentile information to geodataframe with polygon geometry\n",
    "huc_shapes_percs = huc_shapes.merge(huc_perc_df.set_index('geom_id'), left_on='huc8', right_index=True)\n",
    "# set up gdf format for plotting - ex. get rid of datetimes/timestamps\n",
    "huc_shapes_percs['Date'] = huc_shapes_percs['datetime'].dt.strftime('%Y-%m-%d %H:%M')\n",
    "schema = hyswap.utils.retrieve_schema('NWD')\n",
    "flow_cond_cmap = schema['colors']\n",
    "if 'low_color' in schema:\n",
    "                flow_cond_cmap = [schema['low_color']] + flow_cond_cmap\n",
    "if 'high_color' in schema:\n",
    "                flow_cond_cmap = flow_cond_cmap + [schema['high_color']]\n",
    "# set NA values to \"Not Ranked\" category\n",
    "huc_shapes_percs['flow_cat'] = huc_shapes_percs['flow_cat'].cat.add_categories('Not Ranked')\n",
    "huc_shapes_percs.loc[huc_shapes_percs['est_pct'].isna(), 'flow_cat'] = 'Not Ranked'\n",
    "flow_cond_cmap = flow_cond_cmap + ['#d3d3d3'] # light grey\n",
    "# renaming columns with user friendly names for map\n",
    "huc_shapes_percs = huc_shapes_percs.drop(['loaddate', 'datetime'], axis=1)\n",
    "huc_shapes_percs = huc_shapes_percs.rename(columns={'estimated_runoff':'Runoff (mm/day)',\n",
    "                                                'est_pct':'Estimated Percentile',\n",
    "                                                'huc8':'HUC08 ID',\n",
    "                                                'name':'HUC08 Name',\n",
    "                                                'flow_cat':'Streamflow Category'})\n",
    "# Create map of runoff \n",
    "huc_shapes_percs.explore(\n",
    "    column=\"Streamflow Category\",\n",
    "    cmap=flow_cond_cmap,\n",
    "    tooltip=[\"HUC08 ID\", 'HUC08 Name',\"Streamflow Category\", \"Runoff (mm/day)\", \"Estimated Percentile\", \"Date\"],\n",
    "    tiles=\"CartoDB Positron\",\n",
    "    marker_kwds=dict(radius=5),\n",
    "    legend_kwds=dict(caption='Daily Mean Runoff Category'))"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,qmd"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
